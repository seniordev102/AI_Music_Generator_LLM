model:
  target: getmusic.modeling.models.dfm.DFM
  params:
    diffusion_config:
      target: getmusic.modeling.roformer.diffusion_roformer.DiffusionRFM
      params:
        diffusion_step: 100
        alpha_init_type: "alpha1"
        auxiliary_loss_weight: 0.001
        adaptive_auxiliary_loss: True
        roformer_config:
          target: getmusic.modeling.roformer.roformer_utils.DiffusionRoformerModel
          params:
            vocab_size: 11880
            cond_weight: 0.5
            hidden_size: 768
            num_attention_heads: 12
            num_hidden_layers: 12
            intermediate_size: 3072
            hidden_dropout_prob: 0.1
            attention_probs_dropout_prob: 0.1
            max_position_embeddings: 512
            initializer_range: 0.02
            layer_norm_eps: 1.0e-12
            pad_token_id: 0
            pre_layernorm: true

solver:
  base_lr: 3.0e-6
  adjust_lr: sqrt
  max_epochs: 50
  save_epochs: 10
  validation_epochs: 1
  sample_iterations: epoch
  validate_iterations: 1000
  vocab_path: getmusic/utils/dict.txt
  print_specific_things: True

  # config for ema
  ema:
    decay: 0.99
    update_interval: 1
    device: cuda

  clip_grad_norm:
    target: getmusic.engine.clip_grad_norm.ClipGradNorm
    params:
      start_iteration: 0
      end_iteration: 5000
      max_norm: 0.5
  optimizers_and_schedulers:
    - name: none
      optimizer:
        target: torch.optim.AdamW
        step_iteration: 1
        params:
          betas: !!python/tuple [0.9, 0.999]
          weight_decay: 1.0e-2

      scheduler:
        step_iteration: 1
        target: getmusic.engine.lr_scheduler.LinearDecayLRWithWarmup
        params:
          min_lr: 1.0e-6
          warmup_lr: 1.0e-4 # the lr to be touched after warmup
          warmup: 1000
          T_max: 300000

dataloader:
  batch_size: 3 # batch size per GPU
  num_workers: 28
  train_datasets:
    - target: getmusic.data.bigdata.BigDataset
      params:
        prefix: train
        path: src_data/train # can be ignored if you use our checkpoints for just inference
        vocab_size: 11880
  validation_datasets:
    - target: getmusic.data.bigdata.BigDataset
      params:
        prefix: valid
        path: src_data/val
        vocab_size: 11880
